# Задача №2 “Airflow”

## Описание

Теперь необходимо написать DAG, который будет ежедневно в 3 часа ночи по серверному времени брать данные из сырых таблиц Google Big Query, объединять их и перезаписывать данные в результирующей таблице за 30 дней. 

Таблицы:

*Таблица №1 raw_data.google_ads*

| Date | Account Name | Cost |
| --- | --- | --- |
| 2023-02-25 | Google Account 1 | 85.25 |
| 2023-02-22 | Google Account 2 | 230.73169 |
| 2023-02-21 | Google Account 3 | 187.06 |
| 2023-02-20 | Google Account 4 | 223.39 |

*Таблица №2 raw_data.yandex_direct*

| Date | Account Name | Cost |
| --- | --- | --- |
| 2023-02-21 | Yandex Account 1 | 85.25 |
| 2023-02-22 | Yandex Account 2 | 230.73169 |
| 2023-02-25 | Yandex Account 3 | 187.06 |
| 2023-02-26 | Yandex Account 4 | 223.39 |

*Таблица №3 raw_data.crm_deals*

| Date Create | Account Name | Stage of lead |
| --- | --- | --- |
| 2023-02-21 | Yandex Account 1 | New |
| 2023-02-23 | Yandex Account 2 | In progress |
| 2023-02-22 | Google Account 2 | Junk |

## Требования к задаче:

1. Необходимо объединить три источника в результирующей таблице mart_data.marketing_account с помощью SQL в Big Query, чтобы было видно в какой день, с какого источника, по каким аккаунтам, сколько мы тратим и сколько в итоге лидов по этим аккаунтам есть в CRM
2. Итоговая таблица, куда нужно будет записывать объединенные данные должна перезаписывать данные только за 30 последних дней, а не полностью (то есть нельзя использовать CREATE OR REPLACE TABLE)
3. DAG должен отрабатывать каждый день в 3 часа ночи по серверному времени
4. В параметрах DAG необходимо прописать условие, при котором он будет заканчивать работу с ошибкой, если работает больше 1 часа
5. Название DAG - mart_data.marketing_account

## Ожидаемый результат:

DAG в Airflow, состоящий из тасков для формирования таблицы mart_data.marketing_account, в которой хранится информация о перфомансе рекламного источника
